import streamlit as st
import google.generativeai as genai
import pandas as pd

st.set_page_config(page_title="MarmaraTOG AsistanÄ±", page_icon="ğŸ¤–", layout="wide")

# ---------------------------------------------------------
# MODEL SEÃ‡Ä°MÄ° (STRICT MODE - KATI MOD)
# ---------------------------------------------------------
def gemini_ayarla():
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
    else:
        api_key = st.sidebar.text_input("Google API AnahtarÄ±", type="password")
    
    if not api_key:
        st.warning("LÃ¼tfen sol taraftan veya Secrets Ã¼zerinden API anahtarÄ± giriniz.")
        st.stop()
    
    genai.configure(api_key=api_key)
    
    try:
        # Modelleri listele
        mevcut_modeller = []
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                mevcut_modeller.append(m.name)
        
        secilen_model = None
        
        # 1. AÅŸama: Listede aÃ§Ä±kÃ§a "1.5-flash" ara
        for model_adi in mevcut_modeller:
            if "1.5-flash" in model_adi:
                secilen_model = model_adi
                break
        
        # 2. AÅŸama: EÄŸer listede bulamazsan BÄ°LE, baÅŸka modele gitme.
        # DoÄŸrudan 1.5 ismini zorla. (BurasÄ± 2.5 riskini yok eder)
        if not secilen_model:
            secilen_model = "models/gemini-1.5-flash" 

        # KANIT: Hangi modelin seÃ§ildiÄŸini kullanÄ±cÄ±ya gÃ¶ster
        st.sidebar.success(f"âœ… Aktif Model: {secilen_model}")
        
        return genai.GenerativeModel(secilen_model)

    except Exception as e:
        st.error(f"Model hatasÄ±: {e}")
        st.stop()

model = gemini_ayarla()

st.title("ğŸ¤– MarmaraTOG WhatsApp AsistanÄ±")
st.markdown("Bu asistan, yÃ¼klediÄŸiniz WhatsApp geÃ§miÅŸini analiz eder ve sorularÄ±nÄ±zÄ± cevaplar.")

uploaded_file = st.sidebar.file_uploader("WhatsApp Excel DosyasÄ±nÄ± YÃ¼kle", type=["xlsx", "xls"])

if uploaded_file:
    try:
        df = pd.read_excel(uploaded_file)
        text_data = ""
        for index, row in df.iterrows():
            row_text = " | ".join([str(val) for val in row.values])
            text_data += row_text + "\n"

        st.success(f"âœ… Dosya yÃ¼klendi! {len(df)} satÄ±r analiz ediliyor.")

        if "messages" not in st.session_state:
            st.session_state.messages = []

        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        if prompt := st.chat_input("Sorunuzu yazÄ±n..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.chat_message("assistant"):
                with st.spinner("Analiz yapÄ±lÄ±yor..."):
                    try:
                        full_prompt = f"Veri: {text_data[:80000]}\nSoru: {prompt}"
                        response = model.generate_content(full_prompt)
                        st.markdown(response.text)
                        st.session_state.messages.append({"role": "assistant", "content": response.text})
                    except Exception as e:
                        st.error(f"Hata: {e}")
    except Exception as e:
        st.error(f"Dosya okuma hatasÄ±: {e}")
else:
    st.info("ğŸ‘ˆ BaÅŸlamak iÃ§in Excel dosyanÄ±zÄ± yÃ¼kleyin.")